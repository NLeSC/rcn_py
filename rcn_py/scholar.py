import itertools

import pandas as pd
from pyvis.network import Network
from scholarly import scholarly


# use scholarly package
def scholar_search_coauthor(author_fullname):
    # Search author info by their name
    search_query_author = scholarly.search_author(author_fullname)
    author = scholarly.fill(next(search_query_author))

    # Get all the publication info of the author
    docs = []
    for i in range(len(author["publications"])):
        docs.append(author["publications"][i]["bib"])

    # Filter by year
    # new_docs = []
    # for j in docs:
    #         new_docs.append(j)

    # Search the authors of each publication
    df = pd.DataFrame()
    link = []
    for doc in docs:
        try:
            search_pub = scholarly.search_pubs(doc["title"])
        except:
            continue
        else:
            pub_info = next(search_pub)
            # Build a dataframe containing authors' name and id
            temp_df = pd.DataFrame()
            temp_df["name"] = pub_info["bib"]["author"]
            temp_df["id"] = pub_info["author_id"]
        # Build links
        id_list = temp_df["id"]
        id_list_notnull = [i for i in id_list if i != ""]
        link = link + list(itertools.combinations(id_list_notnull, 2))

        # Join dfs
        frames = pd.concat([df, temp_df], ignore_index=True)
        df_notnull = frames[frames["id"] != ""]
        df = df_notnull.drop_duplicates(subset=["id"], keep="first", ignore_index=True)

    return df, link


def scholar_pyvis_network(fullname, node, link, au_group):
    sources = []
    targets = []
    weights = []

    for i in link:
        sources.append(i[0])
        targets.append(i[1])
        weights.append(link.count(i))

    # Pyvis network
    N = Network(height=800, width="100%", bgcolor="#222222", font_color="white")
    N.toggle_hide_edges_on_drag(False)
    N.barnes_hut()

    edge_data = zip(sources, targets, weights)

    for e in edge_data:
        src = e[0]
        dst = e[1]
        w = e[2]

        N.add_node(src, src, title=src, group=au_group[src])
        N.add_node(dst, dst, title=dst, group=au_group[dst])
        N.add_edge(src, dst, value=w)

    N.get_adj_list()

    # add neighbor data to node hover data
    for node in N.nodes:
        # node["title"] = " Neighbors: \n" + " \n".join(neighbors)
        node["title"] = (
            "Link to the authorâ€™s page:\n"
            + scholarly.search_author_id(node["id"])["url_picture"]
        )
        node["value"] = scholarly.search_author_id(node["id"])["citedby"]
        node["label"] = scholarly.search_author_id(node["id"])["name"]

    N.show(fullname + ".html")


def scholar_build_graph(G, sch_id, depth: int, bredth: int, last_author=[]):
    author_search = scholarly.search_author_id(sch_id)
    author = scholarly.fill(author_search, sections=["coauthors", "indices", "counts"])
    author_name = author["name"]
    author_hin = author["hindex"]
    author_ncite = author["citedby"]
    G.add_node(author_name, hindex=author_hin, name=author_name, ncite=author_ncite)
    print("now at %s, depth=%d" % (author_name, depth))
    if depth > 0:
        for coauthor in author["coauthors"][: int(bredth)]:
            G.add_edge(author_name, coauthor["name"])
            if coauthor["name"] not in last_author:
                last_author.append(author_name)
                scholar_build_graph(
                    G, coauthor["scholar_id"], depth - 1, bredth, last_author
                )
